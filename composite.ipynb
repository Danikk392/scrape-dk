{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\"User-Agent\": ua.random}\n",
    "def get_driver():\n",
    "    \"\"\"This function is used to set up a Selenium WebDriver with headless Chrome \n",
    "    in order to go through the data within Yelp.\"\"\"\n",
    "    options = Options()\n",
    "    options.add_argument(\"--headless\")  \n",
    "    options.add_argument(\"--disable-gpu\")\n",
    "    options.add_argument(\"--no-sandbox\")       \n",
    "    options.add_argument(\"--window-size=1920,1080\")\n",
    "    time.sleep(5)\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "    return driver\n",
    "driver = get_driver()\n",
    "\n",
    "def community_section_len(driver):\n",
    "    try:\n",
    "        ask_community_section = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.XPATH, \"//section[contains(@aria-label, 'Ask the Community')]\"))\n",
    "        )\n",
    "        community_section = []\n",
    "        for i in ask_community_section:\n",
    "            try:\n",
    "                community_dates = ask_community_section.find_elements(By.XPATH, \".//span[contains(@class, 'y-css-1d8mpv1')]\")\n",
    "                if community_dates:\n",
    "                    community_section.append(community_dates)\n",
    "                else: \n",
    "                    continue\n",
    "            except Exception as e:\n",
    "                print(f\"Error extracting rating: {e}\") \n",
    "        length = len(community_section)\n",
    "        return length\n",
    "    \n",
    "    except TimeoutException:\n",
    "        print(\"Ask the Community section not found.\")\n",
    "        return 0\n",
    "\n",
    "community_section_len(driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_driver():\n",
    "    \"\"\"This function is used to set up a Selenium WebDriver with headless Chrome \n",
    "    in order to go through the data within Yelp.\"\"\"\n",
    "    options = Options()\n",
    "    options.add_argument(\"--headless\")  \n",
    "    options.add_argument(\"--disable-gpu\")\n",
    "    options.add_argument(\"--no-sandbox\")       \n",
    "    options.add_argument(\"--window-size=1920,1080\")\n",
    "    time.sleep(5)\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "    return driver\n",
    "\n",
    "def yelp_dates(clean_yelp_url):\n",
    "    \"This function extracts the time at which each yelp rating was posted\"\n",
    "    driver = get_driver()\n",
    "    driver.get(clean_yelp_url)\n",
    "    time.sleep(5) # <-- allows time for javascript to load\n",
    "    ask_community_reviews = driver.find_elements(By.XPATH, \"//section[@aria-label='Ask the Community']//ul[contains(@class, 'list__09f24__ynIEd')]/li\")\n",
    "    length = len(ask_community_reviews)\n",
    "    all_page_dates = []\n",
    "    page = 1\n",
    "    while True:\n",
    "        time.sleep(3)\n",
    "        review_sections = driver.find_elements(By.XPATH, \"//ul[contains(@class, 'list__09f24__ynIEd')]//li\") # <--- tells the webscraper to start scraping at the start constumer reviews section\n",
    "        print(f\"Found {len(review_sections)} dates.\")  # Debugging\n",
    "        if not review_sections:\n",
    "            print(\"No dates found on this page.\")\n",
    "            break \n",
    "        \n",
    "        dates = []\n",
    "        for d in review_sections:\n",
    "            try:\n",
    "                date_element = d.find_element(By.XPATH, \".//span[contains(@class, 'y-css-1d8mpv1')][not(contains(text(), 'Photos'))]\")\n",
    "                date = date_element.text.strip()  \n",
    "                if date:\n",
    "                    dates.append(date)\n",
    "                else:\n",
    "                    continue\n",
    "            except Exception as e:\n",
    "                print(f\"Error extracting rating: {e}\") \n",
    "        all_page_dates.append(dates)\n",
    "        print(f\"Stored {len(dates)} from Page {page} into all_page_dates\")\n",
    "        if page > 2:\n",
    "            print(f\"Reached page limit {page}\")\n",
    "            break\n",
    "        if not click_next_page(driver):\n",
    "            print(\"No more pages to scrape reviews from\")\n",
    "            break\n",
    "        page += 1\n",
    "    driver.quit()\n",
    "    return all_page_dates\n",
    "    \n",
    "all_dates = yelp_dates(clean_yelp_url)\n",
    "print(all_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yelp_ratings(clean_yelp_url):\n",
    "    \"This function extracts each yelp rating using Selenium\"\n",
    "    driver = get_driver()\n",
    "    driver.get(clean_yelp_url)\n",
    "    time.sleep(5) # <-- allows time for javascript to load\n",
    "    all_page_ratings = []\n",
    "    page = 1\n",
    "    while True:\n",
    "        time.sleep(2)\n",
    "        review_sections = driver.find_elements(By.XPATH, \"//ul[contains(@class, 'list__09f24__ynIEd')]//li\") # <--- tells the webscraper to start scraping at the start constumer reviews section\n",
    "        print(f\"Found {len(review_sections)} reviews.\")  # Debugging\n",
    "        if not review_sections:\n",
    "            print(\"No reviews found on this page.\")\n",
    "            break \n",
    "        \n",
    "        ratings = []\n",
    "        for review in review_sections:\n",
    "            try:\n",
    "                rating_element = review.find_elements(By.XPATH, \".//div[contains(@class, 'y-css-dnttlc')]\")  \n",
    "                if rating_element:\n",
    "                    rating = rating_element[0].get_attribute(\"aria-label\") \n",
    "                    ratings.append(rating)\n",
    "                else:\n",
    "                    continue\n",
    "            except Exception as e:\n",
    "                print(f\"Error extracting rating: {e}\") \n",
    "        time.sleep(2)\n",
    "        all_page_ratings.append(ratings)\n",
    "        print(f\"Stored {len(ratings)} from Page {page} into all_page_ratings\")\n",
    "        if page > 2:\n",
    "            print(f\"Reached page limit {page}\")\n",
    "            break\n",
    "        if not click_next_page(driver):\n",
    "            print(\"No more pages to scrape reviews from\")\n",
    "            break\n",
    "        page += 1\n",
    "    driver.quit()\n",
    "    return all_page_ratings\n",
    "\n",
    "all_reviews = yelp_ratings(clean_yelp_url)\n",
    "print(all_reviews)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
